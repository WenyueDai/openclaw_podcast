<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0'
     xmlns:itunes='http://www.itunes.com/dtds/podcast-1.0.dtd'
     xmlns:atom='http://www.w3.org/2005/Atom'>
  <channel>
    <title>Daily Podcast</title>
    <link>https://wenyuedai.github.io/openclaw_podcast</link>
    <atom:link href="https://wenyuedai.github.io/openclaw_podcast/feed.xml" rel="self" type="application/rss+xml" />
    <description>Daily autogenerated science podcast</description>
    <language>en</language>
    <lastBuildDate>Sat, 28 Feb 2026 21:50:21 GMT</lastBuildDate>
    <itunes:author>Eva Dai</itunes:author>
    <itunes:summary>Daily autogenerated science podcast</itunes:summary>
    <itunes:owner>
      <itunes:name>Eva Dai</itunes:name>
      <itunes:email>daiwenyueva@gmail.com</itunes:email>
    </itunes:owner>
    <itunes:image href="https://wenyuedai.github.io/openclaw_podcast/cover.svg" />
    <itunes:explicit>false</itunes:explicit>
    
    <item>
      <title>Daily Podcast 2026-02-28</title>
      <guid isPermaLink="false">https://github.com/WenyueDai/openclaw_podcast/releases/download/episode-2026-02-28/podcast_2026-02-28.mp3</guid>
      <pubDate>Sat, 28 Feb 2026 08:00:00 GMT</pubDate>
      <enclosure url="https://github.com/WenyueDai/openclaw_podcast/releases/download/episode-2026-02-28/podcast_2026-02-28.mp3" length="1647357" type="audio/mpeg" />
      <description>A new transformer-based model is setting records in protein structure prediction by achieving state-of-the-art accuracy using only amino acid sequences as input. | The architecture leverages the same attention mechanisms that have proven successful in natural language processing, but here they&#x27;re applied to the problem of inferring three-dimensional protein structure from linear sequence data. | What makes this particularly significant is the performance gain relative to existing methods.</description>
      <itunes:author>Eva Dai</itunes:author>
      <itunes:summary>A new transformer-based model is setting records in protein structure prediction by achieving state-of-the-art accuracy using only amino acid sequences as input. | The architecture leverages the same attention mechanisms that have proven successful in natural language processing, but here they&#x27;re applied to the problem of inferring three-dimensional protein structure from linear sequence data. | What makes this particularly significant is the performance gain relative to existing methods.</itunes:summary>
      <itunes:explicit>false</itunes:explicit>
      <itunes:image href="https://wenyuedai.github.io/openclaw_podcast/cover.svg" />
    </item>
  </channel>
</rss>
