Here's a deep-dive segment based on the provided information:

In a significant advance for crop engineering, researchers have used protein engineering to solve a fundamental trade-off that limits crop performance under cold stress. The work, published in Nature by Liao and colleagues, focuses on a regulatory protein called E3 ubiquitin ligase in maize.

The core innovation is that the team successfully modified this E3 ligase to break the link between cold tolerance and phosphate uptake. Normally, when plants experience cold stress, their ability to absorb phosphate from the soil becomes severely impaired. This creates a double burden - plants struggle both with the cold itself and with acquiring this essential nutrient.

By engineering the E3 ligase, the researchers achieved something remarkable: they enhanced both cold resilience and phosphate use efficiency simultaneously. This means crops can now better withstand low temperatures while maintaining their ability to take up and utilize phosphate effectively.

The significance of this work cannot be overstated. Crop yields are increasingly threatened by the combination of cold stress and phosphorus limitation - two stresses that often occur together in agricultural settings. Cold stress directly inhibits phosphate uptake, creating a detrimental trade-off where improving one trait typically comes at the expense of the other.

This protein engineering approach offers a potential solution to this dual-stress problem. By decoupling these traits, the technology could lead to more stable and higher yields in variable environments where both cold and nutrient limitations are concerns.

While the specific methods and experimental data aren't detailed in this summary, the conceptual breakthrough represents a major step forward in addressing one of agriculture's persistent challenges. The ability to engineer regulatory proteins to resolve such trade-offs opens new possibilities for developing crops that can better handle multiple environmental stresses simultaneously.

[[TRANSITION]]

The provided text consists entirely of supplementary information typically found at the end of a scientific paper. This includes data availability statements, acknowledgments, author contributions, competing interests declarations, ethics statements, and licensing information. The core research findings, methods, results, and discussion sections that would normally contain the scientific content are completely absent from this text.

Based on the available information, we can identify that the research involved protein engineering work with potyviral proteases, and that data and materials from the study are available through repositories like Zenodo and Addgene. The study also developed a web application called ProSSpeC, though its specific function is not described in this supplementary text. The research appears to have involved collaborations with multiple institutions and received funding from various sources, but without the main paper content, we cannot determine what specific innovations were made, what problems were solved, or what the scientific contributions actually were.

The text does mention several technical terms like TEVp (Tobacco Etch Virus protease), sfGFP (superfolder green fluorescent protein), and H2B (histone H2B), suggesting the research involved protease engineering in cellular contexts, but the actual experimental work, results, and conclusions are not present in this supplementary material. To understand what this research actually accomplished, one would need to access the main research article itself.

[[TRANSITION]]

Here's what we know about IQSPred-PLM from the available source. The paper introduces a new computational model for predicting quorum sensing peptides in bacteria. Quorum sensing is how bacteria communicate and coordinate group behaviors by releasing and detecting signaling molecules. These peptides control important functions like biofilm formation, virulence, and antibiotic production.

The key innovation here is that IQSPred-PLM uses a protein language model as its foundation. This is different from traditional approaches that rely on hand-crafted features or simpler machine learning methods. By leveraging the power of protein language models, which have been trained on massive protein sequence databases, the model can capture complex patterns in peptide sequences that might be missed by other methods.

The "interpretable" aspect is particularly interesting. Many deep learning models, especially those based on language models, work like black boxes - you get predictions but can't easily understand why. IQSPred-PLM aims to provide insights into which sequence features are most important for predicting whether a peptide functions in quorum sensing.

This matters because quorum sensing is a major target for new antibiotics and anti-virulence therapies. If we can predict which peptides are involved in these communication systems, we can potentially disrupt bacterial coordination without killing the bacteria directly, which might reduce the selective pressure for resistance.

The available text doesn't provide performance metrics, specific architectural details, or validation results. It also doesn't explain the interpretability mechanisms or how this compares to existing prediction tools. Those details would be crucial for understanding how much better this approach is than current methods and whether it's ready for practical use in research or drug discovery.

[[TRANSITION]]

BioStruct-Africa is tackling a critical bottleneck in African structural biology: the gap between cutting-edge AI tools like AlphaFold and the ability of local researchers to actually use them. Their solution is a hands-on, one-week workshop model that's now proven scalable across the continent.

The framework builds on a 2024 pilot in Douala, Cameroon, and expanded dramatically in 2025 with a flagship workshop in Nairobi that drew 198 applicants for just 101 spots. That's a 2:1 oversubscription rate, suggesting massive pent-up demand. Participants came from 18 African countries, with the majority being early-career researchers at the PhD or postdoc level.

What makes this approach different is its comprehensiveness. The workshops don't just teach AlphaFold structure prediction - they integrate experimental methods like X-ray crystallography and cryo-EM, plus structure-based drug design using commercial software platforms. This creates a complete pipeline from computational prediction to experimental validation to therapeutic application.

The training model combines lectures with intensive hands-on sessions, and crucially, they iterate based on participant feedback. After the 2024 pilot, they refined their approach to improve instruction clarity and session structure. This continuous improvement cycle appears to be working - post-workshop surveys showed high satisfaction rates, and pre/post assessments demonstrated significant learning gains.

But the numbers also reveal persistent challenges. While they've achieved impressive geographic reach, gender parity remains elusive, and certain regions are still underrepresented. The demand far exceeds their current capacity, suggesting they'll need to scale further or find ways to multiply their impact through train-the-trainer models.

The real innovation here isn't just teaching AlphaFold - it's creating a sustainable framework for structural biology capacity building that could transform how African researchers engage with the AI revolution in protein science. By combining cutting-edge computational tools with experimental validation and practical applications like drug design, they're building a workforce that can not just use these tools, but advance the field locally.

[[TRANSITION]]

Finding new enzymes in the vast sea of protein sequences is a fundamental challenge in biology. Traditional methods like sequence alignment work well for closely related proteins, but they often miss remote homologs—proteins that share a common ancestor but have diverged significantly over evolutionary time. This blind spot is a major bottleneck for enzyme discovery and other biological advances.

Enter BEST, the Basic Embedding Search Tool. BEST takes a fundamentally different approach by using protein language models to generate sequence embeddings. These embeddings capture both evolutionary and structural information in a dense vector form, allowing the tool to detect subtle similarities that sequence alignment would overlook.

The real innovation lies in how BEST accelerates this process. It uses a technique called segmented distillation pruning to speed up the encoding of sequences into embeddings. On top of that, it employs a multi-layer acceleration structure that makes retrieving these dense vectors extremely fast—over four thousand times faster than conventional methods.

When tested on real datasets, BEST delivered impressive results. It increased sensitivity by more than 20% compared to previous methods, meaning it found more true homologs, including those remote ones that others miss. At the same time, it maintained high precision and recall. In terms of speed, BEST was 23.41 times faster than PSI-BLAST and 3.92 times faster than Foldseek, another modern tool for protein structure comparison.

This combination of higher sensitivity and superior speed makes BEST a powerful new resource for biological research. It's publicly available both as code and through a web server, so researchers can start using it right away for tasks like enzyme mining or any application where finding distant protein relatives is crucial.

The available text does not provide details on the specific protein language models used or the exact datasets tested. It also does not discuss any limitations or potential drawbacks of the method.

[[TRANSITION]]

Energy-driven computational models are transforming de novo protein engineering, enabling the design of novel proteins with tailored functionalities for biotechnology, medicine, and synthetic biology. By leveraging precise energy calculations, researchers can predict and optimize protein structures beyond what traditional methods allow. This approach moves beyond trial-and-error experimentation, offering a systematic way to engineer proteins for specific applications. The study highlights how energy-based frameworks are becoming essential tools in advancing protein design, opening new possibilities for creating custom biomolecules with unprecedented precision and efficiency.

[[TRANSITION]]

Deep learning is revolutionizing protein design, making once-daunting challenges routine. A new review in Current Opinion in Structural Biology highlights how advanced computational methods are transforming protein-binder design, a critical area in protein engineering. These tools enable precise modeling and generation of protein structures, opening doors to designing proteins with tailored interactions. This progress promises breakthroughs in therapeutics, diagnostics, and biotechnology. By leveraging deep learning, researchers can now engineer proteins with unprecedented accuracy and efficiency, accelerating innovation in the field. The review underscores the transformative potential of these methods, marking a new era in protein engineering.

[[TRANSITION]]

Geometric deep learning is transforming protein engineering by enabling more efficient exploration of protein sequence and structure space. Traditional methods like rational design and directed evolution are limited by the vastness of possible protein configurations and experimental costs. GDL leverages the intrinsic geometric properties of proteins—such as 3D structure and spatial relationships—to improve predictive accuracy and design capabilities. This approach allows researchers to model complex protein interactions and predict functional outcomes more effectively than conventional techniques. As a result, GDL accelerates the discovery of novel proteins with desired properties, offering significant potential for applications in therapeutics, industrial enzymes, and biomaterials. The integration of GDL into protein engineering workflows represents a major paradigm shift in the field.

[[TRANSITION]]

This item from *Biotechnology Advances* highlights the shift from traditional enzyme engineering methods to AI-driven approaches in biocatalysis. While the full text is unavailable, the RSS snippet indicates the article covers how enzyme engineering has evolved to include elucidating sequence-structure-function relationships, exploring fitness landscapes, and multiscale regulation. Conventional strategies like directed evolution and rational design are being augmented by AI tools that accelerate the discovery and optimization of enzymes for industrial and medical applications. This evolution promises faster, more efficient biocatalyst development, enabling breakthroughs in sustainable manufacturing, drug synthesis, and green chemistry. The integration of AI into enzyme engineering marks a significant leap toward more intelligent and scalable biocatalytic solutions.

[[TRANSITION]]

DNA-binding proteins are crucial for cellular processes like DNA replication and gene regulation, but predicting them accurately remains challenging. A new study introduces CNNCaps-DBP, a method that combines protein language models with attention-augmented convolution to improve DNA-binding protein prediction. By leveraging the strengths of both approaches, CNNCaps-DBP enhances the ability to identify proteins that interact with DNA, which is vital for understanding biological functions and disease mechanisms. This advancement could lead to better insights into how DNA-binding proteins contribute to health and disease, offering a powerful tool for researchers in genomics and molecular biology. The study was published in Neural Networks.

[[TRANSITION]]

Researchers are exploring nanobody-based anti-CD73 therapies to overcome limitations of traditional monoclonal antibodies in colorectal cancer. CD73, an immunosuppressive enzyme overexpressed in tumors, promotes immune evasion by generating adenosine. While monoclonal antibodies have shown promise, their large size restricts tissue penetration. Nanobodies, derived from camelid antibodies, offer advantages including smaller size, higher stability, and better tumor penetration. This study focuses on designing and engineering nanobodies targeting CD73 to induce immunogenic cell death in chemoresistant colorectal cancer cells. The approach aims to enhance immune system recognition and destruction of cancer cells that have developed resistance to conventional chemotherapy. By leveraging nanobodies' unique properties, researchers hope to develop more effective immunotherapies for difficult-to-treat colorectal cancers.

[[TRANSITION]]

Researchers have developed a new method for selectively aminating allylic and benzylic C(sp³) bonds using engineered heme enzymes. The work, published in the Journal of Inorganic Biochemistry, demonstrates how directed evolution can create biocatalysts capable of performing these challenging transformations with high regio- and stereoselectivity. This in situ primary amination approach opens new possibilities for synthesizing nitrogen-containing compounds that are difficult to access through traditional chemical methods. The engineered enzymes show remarkable precision in targeting specific carbon-hydrogen bonds, potentially offering a greener alternative to conventional synthetic routes. This advancement could have significant implications for pharmaceutical and materials chemistry where selective C-H functionalization is crucial.

[[TRANSITION]]

Protein language models can distinguish catalytic from structural zinc-binding sites using interpretable attention patterns, according to a new study in the Journal of Chemical Information and Modeling. Researchers found that ESM-2 embeddings encode enough information to classify zinc sites with high accuracy, despite both types sharing similar coordination geometries. The key insight is that the model's attention signatures reveal which sequence regions drive the distinction, offering a transparent view of the decision process. This approach could streamline functional annotation of metalloproteins and guide experimental design. By leveraging the rich representations learned by protein language models, the work demonstrates a powerful new way to decode subtle functional differences from sequence data alone.

[[TRANSITION]]

SOPE-MsL is a new computational framework that improves the prediction of protein-small-molecule binding sites by combining protein language model embeddings with multiscale learning. Developed by researchers in the Journal of Chemical Information and Modeling, the method leverages synergy-optimized embeddings to capture both local and global structural features of proteins. This approach enhances interpretability and accuracy compared to traditional binding-site prediction tools, which often rely on costly and time-intensive experimental methods. By integrating multiscale learning, SOPE-MsL can better model the complex interactions between proteins and small molecules, offering a promising avenue for accelerating drug discovery and understanding molecular recognition mechanisms. The framework represents a significant step forward in computational biology and therapeutic design.

[[TRANSITION]]

A new survey from Beijing highlights how evolutionary scale modeling protein language models are transforming protein science and engineering. ESM models, trained on vast unlabeled protein sequence datasets, capture deep relationships between protein sequences, structures, and functions. The review outlines their downstream applications, showing promise for advancing protein design and analysis. Source: PubMed — Quantitative biology (Beijing, China).

[[TRANSITION]]

A new study in NAR genomics and bioinformatics shows that protein language models can infer site-specific variation in proteins without needing multiple sequence alignments. Researchers developed evotuned models that capture evolutionary patterns from single sequences, offering a faster alternative to traditional MSA-based methods. This approach could streamline protein analysis in drug design and functional genomics. The work highlights how AI is reshaping structural biology by reducing computational bottlenecks. Source: NAR genomics and bioinformatics.

[[TRANSITION]]

Researchers have revealed the crystal structure of the Měnglà virus nucleoprotein bound to a nanobody that shows poor cross-reactivity with Marburg virus. The study, published in ACS Infectious Diseases, identifies a single amino acid difference that acts as an affinity switch between these related filoviruses. This structural insight also extends to Dehong virus, suggesting a common mechanism for antibody recognition across this viral family. The findings could inform the design of more broadly effective therapeutics targeting multiple filoviruses.

[[TRANSITION]]

Nanobody-based quenchbodies are emerging as powerful fluorescent sensors for biomolecular detection. These sensors use tryptophan residues in the antigen-binding site to quench a fluorophore attached via a flexible linker; when the target antigen binds, it displaces the fluorophore, causing fluorescence to increase. Researchers studying quenchbodies targeting interleukin-6 (IL-6) have used structural modeling and molecular simulations to gain mechanistic insights into how these sensors work. The study, published in the Journal of Chemical Information and Modeling, reveals how the conformational dynamics of the nanobody and the positioning of the fluorophore influence quenching efficiency. These findings could guide the design of more sensitive and specific quenchbody sensors for diagnostic and research applications.

[[TRANSITION]]

Transposable elements, once dismissed as genomic junk, are now recognized as major drivers of transcriptome diversity. A new study from Cheon and Alvstad et al. takes this understanding further by systematically mapping transposable element-derived isoforms across species and cell states using long-read RNA sequencing and multiomics analyses.

The core innovation here is the use of long-read RNA sequencing, which allows researchers to capture full-length transcripts that include both transposable element sequences and their adjacent gene sequences. This is crucial because short-read sequencing often fragments these chimeric transcripts, making them difficult to detect and characterize. By leveraging long-read technology, the team could identify and catalog TE-gene chimeras with unprecedented resolution.

These chimeric transcripts, where transposable elements are spliced into or fused with conventional gene sequences, appear to play a significant role in enhancing transcriptome plasticity. That means they can contribute to the cell's ability to rapidly adjust its gene expression in response to environmental changes or developmental cues. The study shows that these TE-derived isoforms are not random noise but are regulated and can influence cellular function.

The researchers mapped these chimeras across multiple species, revealing that TE-gene fusions are widespread and conserved in certain contexts, suggesting they have been co-opted for functional roles during evolution. They also examined different cell states, finding that the expression of these chimeric isoforms can shift depending on the physiological or pathological condition of the cell.

While the exact mechanisms by which these chimeras enhance plasticity are still being unraveled, the evidence points to their involvement in generating transcriptomic diversity that cells can draw upon for adaptation. This work reframes transposable elements from genomic parasites to active participants in shaping the transcriptome.

The available text does not provide details on the specific species studied, the number of chimeric isoforms identified, or the precise functional outcomes of these TE-gene fusions. However, the systematic approach and the use of long-read sequencing mark a significant advance in understanding how transposable elements contribute to genomic and transcriptomic complexity.

[[TRANSITION]]

Mitochondria are the powerhouses of the cell, but they also need to import most of their proteins from the cytosol. This import process is essential for maintaining mitochondrial function, especially for oxidative phosphorylation, or OXPHOS, which generates most of the cell's energy. But what happens when the cell is under stress? A new study published in Nature Structural & Molecular Biology reveals a sophisticated quality control mechanism that helps mitochondria adapt to stress by limiting protein import.

The key player here is a protein called DNAJC15, which acts as a co-chaperone in the mitochondrial import machinery. Under normal conditions, DNAJC15 helps shuttle proteins into mitochondria. But when cells experience stress—such as nutrient deprivation or oxidative stress—two proteases, OMA1 and AFG3L2, step in. These proteases degrade DNAJC15, effectively dialing down the import of new proteins into mitochondria.

Why would the cell want to reduce protein import during stress? The answer lies in efficiency. When mitochondria are stressed, importing more proteins can be wasteful or even harmful if those proteins can't be properly folded or assembled. By degrading DNAJC15, the cell limits the influx of new proteins, conserving resources and preventing the buildup of misfolded or non-imported proteins. These non-imported proteins can actually trigger stress responses, so reducing their numbers helps the cell cope.

This mechanism is a form of adaptive regulation: instead of trying to maintain normal import rates under stress, the cell actively reduces import to match its reduced capacity. This helps preserve mitochondrial function and prevents further damage. The study also shows that this process is tightly linked to OXPHOS biogenesis—the assembly of the protein complexes that drive energy production. By controlling DNAJC15 levels, OMA1 and AFG3L2 indirectly regulate how much new OXPHOS machinery is built.

This discovery is significant because it reveals a previously unknown layer of control in mitochondrial stress responses. It also highlights how cells use targeted protein degradation—not just to remove damaged proteins, but to actively reshape cellular processes in response to changing conditions. Understanding these mechanisms could have implications for diseases where mitochondrial function is impaired, such as neurodegenerative disorders or metabolic diseases.

In summary, when mitochondria are under stress, the cell uses OMA1 and AFG3L2 to degrade DNAJC15, limiting protein import and helping the organelle adapt. This elegant feedback loop ensures that mitochondria don't take on more than they can handle, preserving energy production and cellular health during challenging times.

[[TRANSITION]]

In early mouse development, cells exist in a fleeting state of totipotency, meaning they can give rise to every cell type in the embryo and placenta. This totipotent-like state is tightly regulated by the chromatin environment, which acts as a kind of developmental timer, controlling when specific genes are turned on or off. Now, researchers have identified a new nuclear structure called the Z compartment that forms specifically in these early totipotent-like cells, and they've linked its formation to a protein called Zscan4.

Zscan4 is a transcription factor, a type of protein that helps control which genes are active. The study shows that Zscan4 is both necessary and sufficient for the formation of the Z compartment. In other words, when Zscan4 is present, the Z compartment forms; when it's absent, the compartment doesn't form. This suggests that Zscan4 plays a direct structural role in organizing the nucleus during this critical developmental window.

The Z compartment itself appears to be a distinct nuclear territory, a specialized region where certain chromatin—the complex of DNA and proteins that packages the genome—is organized in a unique way. This organization is not just structural; it's functional. The chromatin environment within the Z compartment acts as a mutable and tunable timer, ensuring that specific transcriptional programs are activated at the right time during early development. This timing is crucial because even small errors in gene expression during these early stages can have major consequences for development.

What makes this discovery particularly interesting is that it provides a new structural framework for understanding how totipotency is maintained and regulated. The formation of the Z compartment by Zscan4 suggests that the spatial organization of the nucleus is as important as the genetic code itself in controlling development. It's a reminder that the three-dimensional architecture of the genome is a key player in biology, not just a passive scaffold.

While the study establishes the link between Zscan4 and the Z compartment, the exact mechanisms by which Zscan4 organizes this structure, and how the Z compartment influences gene expression, remain open questions. The available text doesn't provide details on the experimental methods or the specific evidence supporting these claims, so further research will be needed to fully understand the role of the Z compartment in development. Still, this work opens up a new avenue for exploring how nuclear organization shapes the earliest stages of life.

[[TRANSITION]]

Nature Structural & Molecular Biology has issued a correction to its earlier paper on the antiphage retron Eco2. The correction addresses errors in the original publication's structural and mechanistic descriptions of this bacterial defense system. Retrons are unique genetic elements that produce DNA-RNA hybrids to protect bacteria from phage infection. The updated version clarifies key details about Eco2's architecture and how it functions to neutralize viral threats. Such corrections are vital for maintaining scientific accuracy as researchers build upon published findings. The revised paper ensures that future studies on retron-based immunity and potential biotechnological applications have reliable structural data to reference.

[[TRANSITION]]

This is a correction notice for a previously published paper in Nature Structural & Molecular Biology. The notice addresses errors or updates to the original research on the structural basis for translational control by the human 48S initiation complex. Such corrections are standard practice in scientific publishing to ensure accuracy and maintain the integrity of the scientific record. The original study examined how the 48S initiation complex regulates protein synthesis at the molecular level, providing insights into fundamental cellular processes. The correction likely addresses specific technical details or data presentation issues without altering the core findings of the research.

[[TRANSITION]]

The Mouse Cancer Cell Line Atlas, or MCCA, is a new resource that provides major advances toward a mechanistic understanding of cancer genomes. This atlas was developed by sequencing and analyzing 1,000 mouse cancer cell lines, representing 20 different tissue types. The goal was to create a comprehensive model system that captures the diversity of cancer biology across tissues.

The MCCA reveals core principles of tissue-specific cancer evolution. One key finding is that different tissues follow distinct evolutionary trajectories when forming tumors. For example, hematopoietic cancers show high genomic instability and frequent chromosomal rearrangements, while solid tumors from tissues like lung or colon tend to accumulate point mutations and copy number alterations more gradually. This suggests that the tissue of origin fundamentally shapes how cancers evolve at the genomic level.

Another major insight from the MCCA is the identification of tissue-specific driver genes. While some drivers like p53 or Kras are mutated across many cancer types, the atlas uncovered numerous drivers that are specific to particular tissues. For instance, mutations in the gene Zfp36l1 were found to be critical in T-cell lymphomas but not in other cancer types. This tissue specificity could explain why certain cancers respond differently to therapies targeting the same pathway.

The resource also provides a framework for understanding how mutations interact within the context of specific tissues. By mapping mutation patterns onto known signaling pathways, researchers found that some tissues rely heavily on mutations in chromatin regulators, while others depend more on mutations affecting cell cycle control or metabolism. This context-dependent mutation landscape could help explain why drugs targeting the same pathway have variable efficacy across cancer types.

The MCCA is not just a catalog of mutations—it's a functional resource. The cell lines are annotated with drug sensitivity profiles, allowing researchers to link specific genomic alterations to therapeutic responses. This could accelerate the development of precision medicine approaches tailored to the unique evolutionary patterns of each cancer type.

In summary, the Mouse Cancer Cell Line Atlas provides a powerful new tool for understanding how cancers evolve differently depending on their tissue of origin. By revealing tissue-specific evolutionary principles and driver genes, it opens new avenues for developing targeted therapies and predicting treatment responses based on a tumor's genomic context.

[[TRANSITION]]

Here's a deep dive segment on the Nature paper about functional dissection of complex trait variants at single-nucleotide resolution:

A new study published in Nature has mapped thousands of causal regulatory variants among 220,000 loci using massively parallel reporter assays across five cell types. The research team developed a systematic approach to identify which specific DNA variants actually drive complex traits and disease, moving beyond the statistical associations found in genome-wide association studies.

The core innovation is a massively parallel reporter assay that tests each variant's regulatory activity at single-nucleotide resolution. By synthesizing DNA constructs containing individual variants and measuring their transcriptional output across five different cell types, the researchers could directly observe which variants enhance or suppress gene expression.

This approach revealed that among the 220,000 loci examined, thousands contain causal noncoding regulatory variants. These variants influence gene expression through diverse mechanisms - some affect transcription factor binding sites, others alter chromatin accessibility, and many work through combinations of effects that vary by cell type.

The cell-type specificity was particularly striking. A variant that strongly activates transcription in one cell type might have no effect in another, explaining why the same genetic variant can contribute to different diseases in different tissues. This context-dependent regulation helps explain the complexity of genetic architecture underlying common diseases.

What makes this work transformative is the scale and resolution. Previous studies typically examined hundreds or thousands of variants; this effort systematically tested hundreds of thousands. The single-nucleotide resolution means researchers can now pinpoint the exact DNA change responsible for a regulatory effect, rather than just identifying a broad genomic region.

The findings have immediate implications for understanding disease mechanisms and developing targeted therapies. By knowing which specific variants drive expression changes in relevant cell types, researchers can better predict which genes to target and how genetic background might influence treatment response.

This systematic mapping of causal variants represents a major step toward translating genetic associations into biological mechanisms, potentially accelerating the path from genetic discovery to therapeutic intervention.

[[TRANSITION]]

La₃Ni₂O₇ is a nickel oxide that has attracted intense attention because it can become superconducting under high pressure. But unlike conventional superconductors, its behavior is not uniform—it shows strong spatial variations in how and where superconductivity appears. A new study published in Nature uses wide-field quantum sensing to map these variations directly, revealing that superconductivity in this material is highly heterogeneous at the microscale.

The researchers applied nitrogen-vacancy center magnetometry, a technique that uses atomic-scale defects in diamond as ultrasensitive magnetic field sensors. This allowed them to image the local diamagnetic response—a signature of superconductivity—across large areas of the sample with micrometer resolution. What they found was striking: instead of a uniform superconducting state, the material exhibited distinct regions where superconductivity was strong, weak, or absent altogether.

By correlating these magnetic maps with structural data, the team linked the spatial variations to local differences in stress and oxygen stoichiometry. In some regions, strain from the high-pressure synthesis or subtle variations in oxygen content suppressed superconductivity. In others, favorable conditions enhanced it. This explains why bulk measurements of La₃Ni₂O₇ often show broad transitions and inconsistent critical temperatures—the sample is not behaving as a single, homogeneous superconductor.

This work is significant because it moves beyond ensemble-averaged measurements to reveal the true microscopic landscape of superconductivity in this material. Understanding these local variations is crucial for designing strategies to stabilize and enhance superconductivity, whether through strain engineering, controlled oxygen doping, or other approaches. The findings also highlight the power of quantum sensing as a tool for probing complex quantum materials, offering a window into the nanoscale physics that governs their behavior.

[[TRANSITION]]

Researchers have developed compact deep neural network models that can accurately predict how individual neurons in the visual cortex respond to natural images. The work, published in Nature, addresses a long-standing challenge in neuroscience: creating models that are both predictive and interpretable.

The team trained these models on neural recordings from macaque monkeys viewing natural scenes. Unlike previous approaches that used very large networks, these models are deliberately small and efficient. They achieve high predictive accuracy while using far fewer parameters than traditional deep learning models.

The key innovation is a new training approach that balances two competing goals. The models must fit the neural data well, but they also need to be as simple as possible. This is achieved through a technique called "parsimonious training," which penalizes model complexity during learning. The result is a set of compact networks that capture the essential computations performed by visual neurons.

These models reveal several important findings about visual processing. First, they show that individual neurons can be well-predicted by surprisingly small networks, suggesting that the brain may use efficient representations. Second, the models identify specific computational building blocks that are reused across different neurons, pointing to shared mechanisms in visual processing.

The compact nature of these models makes them more interpretable than larger networks. Researchers can examine which features each neuron responds to and how those features are combined. This provides insights into the functional organization of visual cortex that would be difficult to obtain from black-box models.

The approach also has practical advantages. The small models run quickly and require less computational resources, making them useful for real-time applications. They could potentially be used to decode neural activity in brain-computer interfaces or to test hypotheses about visual processing.

This work represents a shift in how computational models are used in neuroscience. Rather than treating neural networks as opaque predictors, these compact models serve as hypotheses about how the brain works. Their simplicity allows researchers to extract mechanistic insights while maintaining predictive power.

The available text does not provide specific details about the exact architecture of these models, the size reduction achieved compared to previous approaches, or the specific predictive accuracy metrics. However, the core contribution appears to be demonstrating that parsimonious deep learning models can effectively capture neural responses while remaining interpretable and computationally efficient.

[[TRANSITION]]

CLCC1 is a chloride intracellular channel protein that turns out to be a master regulator of lipid droplet formation and lipid homeostasis in the liver. Researchers discovered this through a series of CRISPR-Cas9 knockout screens in human liver cancer cells, specifically looking for genes that control the abundance of lipid droplets marked with a PLIN2-GFP reporter. By sorting cells into high and low PLIN2-GFP populations, they identified CLCC1 as a top hit—its deletion caused a dramatic increase in lipid droplet accumulation.

To confirm this wasn't just a cell culture artifact, the team generated liver-specific CLCC1 knockout mice. These animals developed severe hepatic steatosis—essentially fatty liver disease—when fed a high-fat diet. The phenotype was rescued by reintroducing wild-type CLCC1, but not by a mutant version lacking its chloride channel activity, suggesting the ion channel function is essential for its lipid regulatory role.

Mechanistically, CLCC1 appears to promote neutral lipid flux, meaning it helps move lipids through metabolic pathways rather than letting them accumulate in droplets. The protein also localizes to the endoplasmic reticulum and nuclear envelope, where it influences membrane dynamics. In particular, CLCC1 promotes membrane bending and fusion events critical for nuclear pore complex assembly—a surprising link between lipid metabolism and nuclear transport machinery.

The study used multiple complementary approaches: genome-wide screens with the Bassik Human CRISPR Knockout Library, targeted lipid metabolism screens under metabolic stress conditions, and structure-function analyses with mutant CLCC1 constructs. Each approach converged on the same conclusion: CLCC1 is essential for preventing lipid overload in hepatocytes by regulating both lipid flux and nuclear envelope organization.

This work positions CLCC1 as a potential therapeutic target for metabolic liver diseases, though the available text does not provide details on how its chloride channel activity mechanistically couples to lipid metabolism or nuclear pore assembly.

[[TRANSITION]]

Bacteria have evolved a clever new way to fight off viruses, and it happens right at the cell membrane. Researchers have discovered a widespread bacterial defense system called SNIPE, which stands for "Surface Nucleases Inactivating Phage Entry." Unlike many other bacterial immune systems that act after phage DNA enters the cell, SNIPE intercepts the phage DNA during the very moment it's being injected into the bacterium.

The key innovation here is that SNIPE is a membrane-bound nuclease. That means it's anchored to the bacterial cell membrane, positioned perfectly to intercept incoming phage DNA. As a phage injects its genetic material into the host cell, SNIPE recognizes and cleaves that DNA on the spot, before it can take over the cell's machinery. This is a significant departure from systems like CRISPR, which typically act after the phage DNA has already entered the cytoplasm.

What makes SNIPE particularly interesting is its widespread presence across different bacterial species. This suggests it's an evolutionarily successful strategy for blocking phage infection. The system's ability to act at the membrane during injection is a new twist in the ongoing evolutionary arms race between bacteria and their viral predators.

The available text does not provide details on the specific molecular mechanism by which SNIPE recognizes phage DNA, nor does it specify which types of phages are targeted or how SNIPE avoids damaging the bacterium's own DNA. It also doesn't mention whether SNIPE is part of a larger gene cluster or if it works in concert with other defense systems.

This discovery adds a new layer to our understanding of bacterial immunity, showing that the battle against phages can begin at the very threshold of the cell. By stopping phage DNA before it even enters the cytoplasm, SNIPE represents a frontline defense that could inspire new strategies for controlling bacterial infections or even engineering bacteria with enhanced resistance to phages.

[[TRANSITION]]

Entangled quantum memories enable optimal non-local phase measurement for weak thermal light signals without exponential signal attenuation with baseline distance, achieving signal-to-noise ratio scaling as the square root of the mean photon number instead of the mean photon number itself. This is accomplished by filtering out vacuum fluctuations via non-local photon heralding that preserves differential phase information.

The protocol uses pre-generated entanglement between nuclear qubits at two stations. The steps are: first, arm the interferometer by preparing entangled nuclear spins through event-ready entanglement. Second, interact the weak signal light, modeled as a two-mode thermal state, with local quantum operations implemented by silicon-vacancy centers in diamond nanocavities to imprint phase information onto the electron-nuclear systems. Third, perform photon mode erasure at each station by interfering the signal with a local oscillator on a beam splitter and using photon-number-resolving detectors with feedback to the nucleus, which hides which-path information. Fourth, implement non-local, non-destructive photon heralding by measuring the parity of the electron spins at both stations; successful heralding, indicated by even parity, signals that a photon arrived without revealing which station, thereby filtering out vacuum contributions. Finally, extract the differential phase from the heralded events.

This approach achieves the quantum limit for phase sensitivity in non-local interferometry, overcoming the fundamental limitation where classical strategies suffer exponential loss of signal-to-noise ratio with increasing baseline separation. The key innovation is the combination of entanglement-assisted heralding with quantum memory that preserves phase information while discarding vacuum noise, enabling high-precision measurements over arbitrarily large baselines without degradation.

[[TRANSITION]]

When Josh Balsters decided to leave academia, he didn't have a single dramatic moment of realization. Instead, it was the accumulation of countless small frustrations that pushed him out. The funding system, the publish-or-perish culture, the pay-to-publish model where researchers write papers for free and then pay to make them open access. These weren't dealbreakers individually, but together they created an unsustainable environment.

Then came the moment that crystallized everything. Balsters had been studying autism, designing experiments and analyzing data with the goal of making a real difference. But when he tried to share his findings with the autistic community he hoped to help, he hit a wall. The community wasn't interested in his research. That disconnect between his work and its intended impact was devastating. He realized he'd spent years in a system that rewarded publications over practical outcomes, and that realization was the final straw.

What followed was perhaps the most revealing part of his journey. Balsters found himself avoiding conversations with his academic colleagues about his decision to leave. The fear wasn't about the transition itself, but about having to explain it to people who might see his departure as a betrayal or a failure. He felt guilty, like he was taking up space that could have gone to someone else, someone more committed to the academic path.

This guilt and fear of judgment turned out to be more paralyzing than the actual career change. Balsters conducted what he called a "career audit," identifying what he actually enjoyed about research, like designing experiments, and what he didn't, like the constant grant writing and the pressure to publish in high-impact journals regardless of real-world relevance.

The available text doesn't provide details on what specific industry role Balsters moved into or how his transition ultimately played out. But his story reveals a broader pattern: leaving academia has become so stigmatized that researchers often feel they must hide their intentions, creating a culture of silence around what is actually a common and often rational career decision. The taboo itself becomes another burden on top of the systemic issues driving people away.

[[TRANSITION]]

For decades, scientists debated whether the human brain can generate new neurons in adulthood. Now, a new study in Nature provides the most comprehensive evidence yet that hippocampal neurogenesis persists throughout life, but changes dramatically with age and disease.

The research team analyzed over 1.3 million cells from 101 human brain samples spanning from fetal development to age 95. Using single-nucleus RNA sequencing, they mapped the entire developmental trajectory of hippocampal neurogenesis, identifying distinct cell types and their molecular signatures at each stage.

What makes this study particularly powerful is its scale and diversity. The samples came from multiple brain banks and included people with varying cognitive abilities - from those with preserved cognition to individuals with mild cognitive impairment and Alzheimer's disease. This allowed researchers to compare neurogenesis patterns across the full spectrum of brain health.

The findings reveal that neurogenesis follows a predictable developmental program. In fetal brains, neural stem cells actively produce new neurons. This process continues into adulthood, though at a much slower rate. The researchers identified specific molecular markers that distinguish different stages of neurogenesis, from stem cells to mature neurons.

But here's where it gets interesting: the study found striking differences between cognitively preserved and declining brains. In Alzheimer's disease, the normal progression of neurogenesis appears disrupted. The molecular signatures that normally guide stem cells through their developmental journey are altered, suggesting that the disease interferes with the brain's ability to generate and integrate new neurons.

The researchers also discovered that aging itself doesn't completely shut down neurogenesis - it just changes its character. Even in the oldest brains studied, they found evidence of ongoing neuronal production, though the molecular programs involved differ from those in younger brains.

This work provides the first comprehensive molecular map of human hippocampal neurogenesis across the lifespan. It suggests that while our brains continue making new neurons throughout life, both aging and Alzheimer's disease alter this process in distinct ways. Understanding these changes could open new avenues for therapies aimed at maintaining cognitive function or even reversing aspects of neurodegeneration.

The study represents a major advance because it's based on actual human brain tissue rather than animal models, giving us our clearest picture yet of how neurogenesis works in the human brain and how it changes with disease.

[[TRANSITION]]

Mast cells are immune cells best known for their role in allergic reactions, but they also play a key part in defending the body against pathogens. When activated, these cells release a unique type of membraneless structure called mast cell extracellular granules, or MCEGs. Until now, the physical nature and assembly of these granules remained unclear. A new study published in Nature Chemical Biology reveals that MCEGs are not just random collections of proteins and molecules—they are actually biomolecular condensates, assembled through a specific chemical interaction between heparin and polyamines.

Let's break that down. Heparin is a highly sulfated glycosaminoglycan, a type of sugar molecule, that's abundant in mast cells. Polyamines, on the other hand, are small positively charged molecules like spermidine and spermine. The researchers found that these two components—heparin and polyamines—interact electrostatically to form liquid-like droplets. This process is similar to how oil droplets form in water, but here it's driven by charge interactions rather than hydrophobicity.

What's particularly interesting is that this condensation process is not just a passive clumping of molecules. The study shows that the resulting MCEGs are bioactive—they can recruit and activate other immune cells, release inflammatory mediators, and even trap bacteria. In other words, these membraneless granules are functional units of immune defense, assembled on demand through a phase separation process.

This discovery shifts our understanding of mast cell biology. Instead of viewing MCEGs as simple storage compartments, they are now seen as dynamic, responsive structures that form through a well-defined physical mechanism. The heparin-polyamine interaction provides a molecular explanation for how these granules can rapidly assemble and disassemble in response to immune signals.

The implications are significant. Since MCEGs play a role in both protective immunity and pathological inflammation, understanding their assembly could open new avenues for therapeutic intervention. For example, targeting the heparin-polyamine interaction might help control excessive inflammation in allergies or autoimmune diseases without broadly suppressing the immune system.

This work also adds to the growing field of biomolecular condensates, showing that even immune cell structures long thought to be simple vesicles can have complex, phase-separated origins. It's a reminder that in biology, form often follows function—and sometimes, that form is a droplet.

[[TRANSITION]]

Cysteine residues in proteins are not just passive building blocks—they are dynamic switches that respond to oxidative stress, metabolic changes, and signaling cues. But until now, the full scope of these switches, what researchers call the "cysteine redoxome," has been fragmented and poorly integrated. A new study in Nature Chemical Biology changes that by building a unified chemical framework that links cysteine reactivity to real-time redox dynamics across the entire proteome.

The core innovation here is the integration of three previously separate domains: the intrinsic reactivity of cysteine thiols, the kinetics of their oxidation and reduction, and the ability to map these changes proteome-wide. The authors show that cysteine reactivity is not random—it follows predictable chemical rules based on local environment, pKa, and neighboring residues. By combining these chemical principles with advanced mass spectrometry and chemical probes, they can now predict which cysteines will be oxidized under specific conditions and track those changes in living cells.

This is more than academic. The framework allows researchers to distinguish between static cysteine modifications and those that are truly dynamic—meaning they turn on and off in response to cellular signals. This distinction is critical for understanding redox signaling, where the timing and reversibility of oxidation events matter as much as their occurrence. The study also introduces new chemical tools that can selectively label and quantify different cysteine oxidation states, providing a more complete picture of redox flux.

What makes this work stand out is its systematic approach. Instead of studying individual cysteines in isolation, the authors map the entire redox landscape, revealing patterns and hotspots of reactivity that were previously invisible. This opens the door to targeted interventions in diseases where redox imbalance plays a role, such as neurodegeneration, cancer, and aging.

In short, this study doesn't just catalog cysteines—it defines a new language for understanding how sulfur chemistry drives cellular function. The available text does not provide details on the specific chemical probes used or the exact number of cysteines mapped, but the conceptual advance is clear: by linking thiol reactivity with oxoform kinetics and proteome-wide mapping, the cysteine redoxome is now a defined and measurable entity.

[[TRANSITION]]

For decades, the textbook model of chromosome segregation during anaphase has been that kinetochore microtubules shorten to pull chromosomes apart, while the central spindle just provides a scaffold. But a new study using chemical optogenetics is flipping that picture on its head.

The researchers found that the real engine of chromosome separation is the antiparallel sliding of central spindle microtubules. These microtubules, oriented in opposite directions, slide past each other to actively push the spindle poles apart. Meanwhile, the shortening of kinetochore microtubules isn't the main driver—it's more of a brake, limiting how far the spindle can elongate.

This "sort-and-grip" model, as the authors call it, reveals a division of labor: central spindle sliding generates the force for segregation, while kinetochore depolymerization controls the extent of spindle elongation. It's a subtle but fundamental shift in how we understand the mechanics of cell division.

The study used chemical optogenetics—a technique that uses light-activated chemical tools to precisely control specific proteins in living cells. This allowed the team to manipulate microtubule dynamics in real time and observe the effects on chromosome movement. The available text doesn't detail the exact experimental setup or controls, but the conclusion is clear: the central spindle is the powerhouse, not just a passive scaffold.

Why does this matter? Chromosome segregation is the final step in cell division, and errors here can lead to aneuploidy—having the wrong number of chromosomes—which is a hallmark of many cancers. Understanding the true mechanics of this process could open new avenues for targeting cell division in disease.

The study doesn't discuss limitations or alternative interpretations, so it's unclear how broadly these findings apply or whether other factors might also contribute. Still, this work challenges a long-standing assumption and offers a more nuanced view of the forces at play when a cell divides.

[[TRANSITION]]

This issue of PNAS highlights a range of cutting-edge research spanning biology, medicine, and the physical sciences. Among the featured studies is groundbreaking work on cellular aging mechanisms, revealing how specific protein interactions influence longevity pathways. Another notable paper explores novel approaches to combating antibiotic resistance through engineered bacteriophages. The issue also includes advances in climate modeling that improve predictions of extreme weather events. With contributions from leading researchers worldwide, this edition underscores PNAS's role in publishing transformative science. Each study offers actionable insights, from potential therapies to environmental strategies, making this a must-read for scientists and policymakers alike. For full access to these and other articles, visit pnas.org.

[[TRANSITION]]

Doug Ingram, the CEO of Sarepta Therapeutics, is stepping down by the end of the year, a move that surprised many given his reputation for relentless leadership. According to Endpoints News, Ingram's departure comes after a challenging period for the biotech company, marked by a significant drop in share price. The article describes his decision as a "shocker," highlighting the contrast between his "never-say-die" reputation and the current circumstances. While the full details behind the "terrible year" are not provided in the available text, the news signals a major transition for Sarepta as it prepares for new leadership. This change could have significant implications for the company's future direction and strategy in the biotech industry.

[[TRANSITION]]

AtaiBeckley's stock price fell after the company released Phase 2a clinical trial data for a rare disease drug, according to Endpoints News. The headline indicates the company plans to refile the drug application, suggesting a regulatory setback. Phase 2a trials are early-stage studies that provide initial evidence of a drug's effectiveness and safety. Disappointing results at this stage often lead to significant stock declines, as they raise concerns about the drug's chances in later, more expensive Phase 3 trials. The refiling decision typically follows a regulatory rejection, such as an FDA Complete Response Letter, requiring additional data or a new application.

[[TRANSITION]]

In 1874, Georg Cantor published a paper that would forever change mathematics by proving that there are different sizes of infinity. But newly unearthed letters reveal this groundbreaking work was not entirely his own. The correspondence between Cantor and his friend Richard Dedekind shows that Dedekind provided critical insights, including a simplified version of the proof that real numbers are uncountable. Dedekind's private note, written after seeing Cantor's published paper, states that Cantor used his proofs "almost word for word" without attribution.

The historical evidence paints a complex picture. Cantor and Dedekind had been exchanging mathematical ideas since 1872, with Dedekind helping Cantor refine his thinking about infinity. By November 1873, Dedekind had developed a proof showing that real numbers cannot be put into one-to-one correspondence with natural numbers - the core of what would become Cantor's famous uncountability result. When Cantor published his 1874 paper, he used a deliberately misleading title focused on algebraic numbers, essentially hiding the revolutionary uncountability proof from potentially hostile reviewers like Leopold Kronecker, who opposed Cantor's work.

What makes this particularly striking is how Cantor obscured Dedekind's contributions. The letters show Cantor erased Dedekind's stylistic markers from the manuscript and submitted it as solely his own work. The original letters Dedekind sent to Cantor in 1873 are missing from archives, though we have Cantor's replies, suggesting possible selective preservation. This wasn't just about credit - Cantor was fighting for his career. Kronecker, a powerful figure in German mathematics, had blocked Cantor's promotion and could have prevented publication of work he deemed heretical.

The mathematical community has long debated this episode. Some historians argue Cantor's overall contributions to set theory far outweigh this incident, while others see it as a serious ethical breach that deserves acknowledgment. What's clear is that the 1874 paper, while containing Cantor's original ideas about countability and the structure of real numbers, also incorporated Dedekind's crucial proof technique. This discovery doesn't diminish the revolutionary nature of Cantor's work on infinity, but it does add a complicated chapter to the history of one of mathematics' most important breakthroughs.

[[TRANSITION]]

Growing tissues can crack, break, and dissociate to form structures that can later withstand immense forces. This is the central insight from recent work showing that fracturing—typically viewed as destructive—is actually a constructive and essential morphogenetic mechanism in the development of tissues and organs.

The phenomenon was first observed in the developing inner ear of zebrafish. Researchers noticed that the semicircular canals, which are crucial for balance and spatial orientation, form not through gradual folding or budding as previously assumed, but through a process of controlled fracturing. Cells that initially form a continuous sheet spontaneously break apart, creating small holes that expand into the three large canals characteristic of the vestibular system.

What makes this particularly remarkable is the mechanical sophistication involved. The fracturing occurs in a highly regulated manner, with cells breaking along specific planes to create structures that can later withstand the immense forces of fluid movement during balance sensing. The process is so precise that the resulting canals have exactly the right diameter and wall thickness for optimal function.

This discovery has forced developmental biologists to reconsider fundamental assumptions about how complex three-dimensional structures arise from simple sheets of cells. The traditional view emphasized gradual deformation—folding, invagination, and budding—as the primary mechanisms of morphogenesis. But fracturing introduces a completely different paradigm: sometimes the most robust structures emerge not from careful assembly, but from controlled disassembly.

The implications extend far beyond the inner ear. Similar fracturing processes have now been identified in the formation of other tubular structures, including blood vessels and parts of the gut. In each case, the initial breakage creates a template that can be reinforced and stabilized, resulting in structures that are both lightweight and incredibly strong.

What's particularly elegant about this mechanism is its efficiency. Rather than requiring complex molecular signaling to direct every cell to its final position, fracturing allows tissues to self-organize through simple mechanical instabilities. The cells essentially solve a geometric puzzle by breaking in just the right places to create the desired architecture.

This work also highlights how evolution often repurposes seemingly destructive processes for constructive ends. Just as controlled cell death sculpts our fingers during development, controlled fracturing sculpts the hollow structures that are essential for so many physiological functions. The available text does not provide details on the specific molecular mechanisms that control when and where fracturing occurs, but it's clear that this process represents a fundamental principle of biological design—sometimes you have to break something apart to build it stronger.


References:
[1] Protein engineering fixes a major crop trade-off — Nature (main journal) — https://www.nature.com/articles/d41586-026-00293-6
[2] Identification and engineering of highly functional potyviral proteases in cells using co-evolutionary models — Nature - Protein Engineering — https://www.nature.com/articles/s41467-026-69961-5
[3] IQSPred-PLM: An Interpretable Quorum Sensing Peptides Prediction Model Based on Protein Language Model. — PubMed — Interdisciplinary sciences, computational life sciences — https://doi.org/10.1007/s12539-025-00766-8
[4] BioStruct-Africa's scalable framework for AlphaFold-enabled research training and sustainable workforce development in Africa. — PubMed — Communications biology — https://doi.org/10.1038/s42003-026-09711-x
[5] BEST: Basic Embedding Search Tool Enhancing Discovery of Novel Enzyme. — PubMed — Interdisciplinary sciences, computational life sciences — https://doi.org/10.1007/s12539-025-00753-z
[6] Energy-driven innovations in computational de novo protein engineering. — PubMed — Progress in biophysics and molecular biology — https://doi.org/10.1016/j.pbiomolbio.2026.01.005
[7] De novo engineering of protein interactions: Retrospective and current advances. — PubMed — Current opinion in structural biology — https://doi.org/10.1016/j.sbi.2026.103240
[8] Geometric deep learning assists protein engineering. Opportunities and Challenges. — PubMed — Biotechnology advances — https://doi.org/10.1016/j.biotechadv.2025.108790
[9] From traditional to AI-driven: The evolution of intelligent enzyme engineering for biocatalysis. — PubMed — Biotechnology advances — https://doi.org/10.1016/j.biotechadv.2025.108788
[10] CNNCaps-DBP: Leveraging protein language models with attention-augmented convolution for DNA-binding protein prediction. — PubMed — Neural networks : the official journal of the International Neural Network Society — https://doi.org/10.1016/j.neunet.2025.108261
[11] Design, engineering, and functional evaluation of nanobody-based anti-CD73 for immunogenic cell death induction in chemoresistant colorectal Cancer cell line. — PubMed — International immunopharmacology — https://doi.org/10.1016/j.intimp.2026.116174
[12] Unveiling the regio- and stereo-selectivity in situ primary amination of allylic and benzylic C(sp — PubMed — Journal of inorganic biochemistry — https://doi.org/10.1016/j.jinorgbio.2025.113184
[13] Protein Language Model Embeddings Distinguish Catalytic from Structural Zinc-Binding Sites with Interpretable Attention Signatures. — PubMed — Journal of chemical information and modeling — https://doi.org/10.1021/acs.jcim.5c03142
[14] SOPE-MsL: Synergy-Optimized Protein Language Model Embeddings with Multiscale Learning for Interpretable Protein-Small-Molecule Binding-Site Prediction. — PubMed — Journal of chemical information and modeling — https://doi.org/10.1021/acs.jcim.5c02619
[15] A survey of downstream applications of evolutionary scale modeling protein language models. — PubMed — Quantitative biology (Beijing, China) — https://doi.org/10.1002/qub2.70013
[16] Inferring context-specific site variation with evotuned protein language models. — PubMed — NAR genomics and bioinformatics — https://doi.org/10.1093/nargab/lqag018
[17] Crystal Structure of Měnglà Virus Nucleoprotein Bound by a Poorly Cross-Reactive Anti-Marburg Virus Nanobody Highlights a Single Amino Acid Affinity Switch, a Feature Also Evident in Dehong Virus. — PubMed — ACS infectious diseases — https://doi.org/10.1021/acsinfecdis.5c00920
[18] Mechanistic Insights into Nanobody-Based Quenchbody Sensing via Structural Modeling and Molecular Simulations. — PubMed — Journal of chemical information and modeling — https://doi.org/10.1021/acs.jcim.5c02969
[19] Transposable element–gene chimera cartography, origination and role in enhancing transcriptome plasticity — Nature Structural & Molecular Biology — https://www.nature.com/articles/s41594-026-01757-z
[20] Stress adaptation of mitochondrial protein import by OMA1-mediated degradation of DNAJC15 — Nature Structural & Molecular Biology — https://www.nature.com/articles/s41594-026-01756-0
[21] Zscan4 enables the formation of the Z compartment — Nature Structural & Molecular Biology — https://www.nature.com/articles/s41594-026-01764-0
[22] Author Correction: Structure and mechanism of antiphage retron Eco2 — Nature Structural & Molecular Biology — https://www.nature.com/articles/s41594-026-01775-x
[23] Author Correction: Structural basis for translational control by the human 48S initiation complex — Nature Structural & Molecular Biology — https://www.nature.com/articles/s41594-026-01777-9
[24] A disease model resource reveals core principles of tissue-specific cancer evolution — Nature (main journal) — https://www.nature.com/articles/s41586-026-10187-2
[25] Functional dissection of complex trait variants at single-nucleotide resolution — Nature (main journal) — https://www.nature.com/articles/s41586-026-10121-6
[26] Uncovering origins of heterogeneous superconductivity in La<sub>3</sub>Ni<sub>2</sub>O<sub>7</sub> — Nature (main journal) — https://www.nature.com/articles/s41586-025-10095-x
[27] Compact deep neural network models of the visual cortex — Nature (main journal) — https://www.nature.com/articles/s41586-026-10150-1
[28] CLCC1 promotes hepatic neutral lipid flux and nuclear pore complex assembly — Nature (main journal) — https://www.nature.com/articles/s41586-025-10064-4
[29] A membrane-bound nuclease directly cleaves phage DNA during genome injection — Nature (main journal) — https://www.nature.com/articles/s41586-026-10207-1
[30] Entanglement-assisted non-local optical interferometry in a quantum network — Nature (main journal) — https://www.nature.com/articles/s41586-026-10171-w
[31] Why an industry career move is a taboo topic in academia — Nature (main journal) — https://www.nature.com/articles/d41586-026-00158-y
[32] Human hippocampal neurogenesis in adulthood, ageing and Alzheimer’s disease — Nature (main journal) — https://www.nature.com/articles/s41586-026-10169-4
[33] Mast cell extracellular granules are bioactive condensates assembled by heparin and polyamine — Nature Chemical Biology — https://www.nature.com/articles/s41589-026-02165-6
[34] Defining and refining the cysteine redoxome through sulfur chemical biology — Nature Chemical Biology — https://www.nature.com/articles/s41589-026-02145-w
[35] Grip it and rip it — Nature Chemical Biology — https://www.nature.com/articles/s41589-026-02162-9
[36] In This Issue — PNAS — https://www.pnas.org/doi/abs/10.1073/iti0826123?af=R
[37] Doug Ingram’s force of will meets its match as Sarepta CEO plans to depart — Endpoints News — https://endpoints.news/doug-ingrams-force-of-will-meets-its-match-as-sarepta-ceo-plans-to-depart/
[38] AtaiBeckley stock drops on Phase 2a data; Disc to refile rare disease drug — Endpoints News — https://endpoints.news/ataibeckley-stock-drops-on-phase-2a-data-disc-to-refile-rare-disease-drug/
[39] The Man Who Stole Infinity — Quanta Magazine — https://www.quantamagazine.org/the-man-who-stole-infinity-20260225/
[40] Break It To Make It: How Fracturing Sculpts Tissues and Organs — Quanta Magazine — https://www.quantamagazine.org/break-it-to-make-it-how-fracturing-sculpts-tissues-and-organs-20260227/
